# -*- coding: utf-8 -*-
"""grid image generator

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1WlMj2_t5tQFPWoLfpBBAc5o36tNQs6p-
"""

!pip install -Uqqq pip --progress-bar off
!pip install -qqq torch==2.1.1 --progress-bar off
!pip install -qqq diffusers==0.24.0 --progress-bar off
!pip install -qqq transformers==4.35.2 --progress-bar off
!pip install -qqq accelerate==0.24.1 --progress-bar off

from google.colab import drive
drive.mount('/content/drive')

import torch
from diffusers import AutoPipelineForText2Image
import os
import cv2
from PIL import Image, ImageDraw, ImageFont
import numpy as np

image_generator = AutoPipelineForText2Image.from_pretrained(
    "stabilityai/sdxl-turbo", torch_dtype=torch.float16, variant="fp16"
).to("cuda")

font_path = os.path.join(cv2.__path__[0], "qt", "fonts", "DejaVuSans.ttf")
font = ImageFont.truetype(font_path, size=28)

image_generator.load_lora_weights("/content/drive/MyDrive/LoRA/dungeons_and_dragons_xl_v3.safetensors", weight_name="dungeons_and_dragons_xl_v3.safetensors")

def display_image_grid(images, grid_width, image_spacing=10):
    """
    Display images in a grid layout without titles.

    Args:
    images (list): A list of PIL Image objects.
    grid_width (int): The number of images per row in the grid.
    image_spacing (int, optional): The spacing between images in the grid. Default is 10.

    Returns:
    Image: A single PIL Image object representing the grid of images.
    """
    if not images:
        raise ValueError("The images list is empty")

    img_width, img_height = images[0].size

    n = len(images)
    grid_height = n // grid_width + (n % grid_width > 0)

    total_width = img_width * grid_width + image_spacing * (grid_width - 1)
    total_height = img_height * grid_height + image_spacing * (grid_height - 1)

    grid_image = Image.new("RGB", (total_width, total_height), (255, 255, 255))

    for i, image in enumerate(images):
        row = i // grid_width
        col = i % grid_width
        x = col * (img_width + image_spacing)
        y = row * (img_height + image_spacing)

        grid_image.paste(image, (x, y))

    return grid_image

images = []
for steps in range(1, 60):
    generator = torch.Generator(device="cuda").manual_seed(steps)

    prompt = """
sfw, solo focus, hd, 8k, vintage illustration, masterpiece, award winning illustration of a sexy female adventure exploring a spooky cavern, intricate details, Dungeons and Dragons
""".strip()

    outputs = image_generator(
        prompt=prompt, num_inference_steps=4, guidance_scale=0, generator=generator
    )
    images.append(outputs.images[0])

grid_image = display_image_grid(images, grid_width=5)
grid_image.show()

grid_image

import os
folder_path = "/content/drive/MyDrive/LoRA/advFe"
os.makedirs(folder_path, exist_ok=True)

# Save each individual image
for i, image in enumerate(images):
    image_path = os.path.join(folder_path, f"image_{i+1}.jpg")
    image.save(image_path)

import torch
import os
from transformers import AutoImageProcessor, AutoModel
from PIL import Image
from sklearn.cluster import KMeans
import numpy as np

# Function to load images from a folder
def load_images_from_folder(folder):
    images = []
    for filename in os.listdir(folder):
        img_path = os.path.join(folder, filename)
        try:
            img = Image.open(img_path).convert("RGB")
            images.append(img)
        except IOError:
            pass  # You can handle errors here if you want
    return images

# Image folder path
image_folder = '/content/drive/MyDrive/LoRA/advFe'

# Load images
images = load_images_from_folder(image_folder)

# Initialize the processor and model
processor = AutoImageProcessor.from_pretrained('facebook/dinov2-base')
model = AutoModel.from_pretrained('facebook/dinov2-base')
model.config.return_dict = False

# Feature extraction
features = []
for image in images:
    inputs = processor(images=image, return_tensors="pt")
    with torch.no_grad():
        outputs = model(**inputs)
    # Flatten the tensor to 1D and convert to numpy
    features.append(outputs[0].squeeze().view(-1).numpy())

# Convert list of features to a 2D array
features_array = np.array(features)

# Clustering with K-MEANS++
n_clusters = 5  # Define the number of clusters
kmeans = KMeans(n_clusters=n_clusters, init='k-means++')
kmeans.fit(features_array)

# The cluster assignment for each image
clusters = kmeans.labels_

print("Cluster assignments:", clusters)

import numpy as np
import matplotlib.pyplot as plt
from sklearn.manifold import TSNE

# Dimensionality Reduction using t-SNE
n_samples = len(features_array)
perplexity_value = min(30, n_samples - 1)  # Ensure perplexity is less than the number of samples

tsne = TSNE(n_components=2, verbose=1, perplexity=perplexity_value, n_iter=300)
tsne_results = tsne.fit_transform(features_array)

# Visualization
plt.figure(figsize=(16,10))
scatter = plt.scatter(tsne_results[:,0], tsne_results[:,1], c=clusters, cmap='viridis')
plt.title('t-SNE visualization of image clusters')
plt.colorbar(scatter)
plt.show()

# Sort images by cluster assignment
sorted_indices = np.argsort(clusters)
sorted_images = [images[idx] for idx in sorted_indices]
sorted_clusters = clusters[sorted_indices]

# Get the count of images in each cluster
cluster_counts = np.bincount(sorted_clusters)

# Create a figure with subplots
fig, axes = plt.subplots(max(cluster_counts), len(np.unique(clusters)), figsize=(20, 60), squeeze=False)

# Plot each cluster in its column
for cluster_num in np.unique(sorted_clusters):
    cluster_indices = np.where(sorted_clusters == cluster_num)[0]
    for idx, img_idx in enumerate(cluster_indices):
        ax = axes[idx, cluster_num]
        ax.imshow(sorted_images[img_idx])
        ax.axis('off')
    for idx in range(len(cluster_indices), max(cluster_counts)):
        axes[idx, cluster_num].axis('off')

# Optionally, add a title to each column
for cluster_num in np.unique(sorted_clusters):
    axes[0, cluster_num].set_title(f'Cluster {cluster_num}')

plt.tight_layout()
plt.show()

def save_cluster_images(images, clusters, base_path):
    # Sort images by cluster assignment
    sorted_indices = np.argsort(clusters)
    sorted_images = [images[idx] for idx in sorted_indices]
    sorted_clusters = clusters[sorted_indices]

    # Iterate over each cluster and save images
    for cluster_num in np.unique(sorted_clusters):
        cluster_indices = np.where(sorted_clusters == cluster_num)[0]
        cluster_images = [sorted_images[idx] for idx in cluster_indices]

        # Create a directory for the cluster if it doesn't exist
        cluster_dir = os.path.join(base_path, f'cluster_{cluster_num}')
        os.makedirs(cluster_dir, exist_ok=True)

        # Save each image in the respective cluster directory
        for idx, img in enumerate(cluster_images):
            img_path = os.path.join(cluster_dir, f'image_{idx}.png')
            img.save(img_path)

save_cluster_images(images, clusters, image_folder)

import torch
import os
from transformers import AutoImageProcessor, AutoModel
from PIL import Image
from sklearn.cluster import KMeans
import numpy as np

# Function to load images from a folder
def load_images_from_folder(folder):
    images = []
    for filename in os.listdir(folder):
        img_path = os.path.join(folder, filename)
        try:
            img = Image.open(img_path).convert("RGB")
            images.append(img)
        except IOError:
            pass  # You can handle errors here if you want
    return images

# Image folder path
image_folder = '/content/drive/MyDrive/LoRA/advFe2'

# Load images
images = load_images_from_folder(image_folder)

# Initialize the processor and model
processor = AutoImageProcessor.from_pretrained('facebook/dinov2-base')
model = AutoModel.from_pretrained('facebook/dinov2-base')
model.config.return_dict = False

# Feature extraction
features = []
for image in images:
    inputs = processor(images=image, return_tensors="pt")
    with torch.no_grad():
        outputs = model(**inputs)
    # Flatten the tensor to 1D and convert to numpy
    features.append(outputs[0].squeeze().view(-1).numpy())

# Convert list of features to a 2D array
features_array = np.array(features)

# Clustering with K-MEANS++
n_clusters = 5  # Define the number of clusters
kmeans = KMeans(n_clusters=n_clusters, init='k-means++')
kmeans.fit(features_array)

# The cluster assignment for each image
clusters = kmeans.labels_

print("Cluster assignments:", clusters)

import numpy as np
import matplotlib.pyplot as plt
from sklearn.manifold import TSNE

# Dimensionality Reduction using t-SNE
n_samples = len(features_array)
perplexity_value = min(30, n_samples - 1)  # Ensure perplexity is less than the number of samples

tsne = TSNE(n_components=2, verbose=1, perplexity=perplexity_value, n_iter=300)
tsne_results = tsne.fit_transform(features_array)

# Visualization
plt.figure(figsize=(16,10))
scatter = plt.scatter(tsne_results[:,0], tsne_results[:,1], c=clusters, cmap='viridis')
plt.title('t-SNE visualization of image clusters')
plt.colorbar(scatter)
plt.show()

# Sort images by cluster assignment
sorted_indices = np.argsort(clusters)
sorted_images = [images[idx] for idx in sorted_indices]
sorted_clusters = clusters[sorted_indices]

# Get the count of images in each cluster
cluster_counts = np.bincount(sorted_clusters)

# Create a figure with subplots
fig, axes = plt.subplots(max(cluster_counts), len(np.unique(clusters)), figsize=(20, 60), squeeze=False)

# Plot each cluster in its column
for cluster_num in np.unique(sorted_clusters):
    cluster_indices = np.where(sorted_clusters == cluster_num)[0]
    for idx, img_idx in enumerate(cluster_indices):
        ax = axes[idx, cluster_num]
        ax.imshow(sorted_images[img_idx])
        ax.axis('off')
    for idx in range(len(cluster_indices), max(cluster_counts)):
        axes[idx, cluster_num].axis('off')

# Optionally, add a title to each column
for cluster_num in np.unique(sorted_clusters):
    axes[0, cluster_num].set_title(f'Cluster {cluster_num}')

plt.tight_layout()
plt.show()

def save_cluster_images(images, clusters, base_path):
    # Sort images by cluster assignment
    sorted_indices = np.argsort(clusters)
    sorted_images = [images[idx] for idx in sorted_indices]
    sorted_clusters = clusters[sorted_indices]

    # Iterate over each cluster and save images
    for cluster_num in np.unique(sorted_clusters):
        cluster_indices = np.where(sorted_clusters == cluster_num)[0]
        cluster_images = [sorted_images[idx] for idx in cluster_indices]

        # Create a directory for the cluster if it doesn't exist
        cluster_dir = os.path.join(base_path, f'cluster_{cluster_num}')
        os.makedirs(cluster_dir, exist_ok=True)

        # Save each image in the respective cluster directory
        for idx, img in enumerate(cluster_images):
            img_path = os.path.join(cluster_dir, f'image_{idx}.png')
            img.save(img_path)

save_cluster_images(images, clusters, image_folder)

import torch
import os
from transformers import AutoImageProcessor, AutoModel
from PIL import Image
from sklearn.cluster import KMeans
import numpy as np

# Function to load images from a folder
def load_images_from_folder(folder):
    images = []
    for filename in os.listdir(folder):
        img_path = os.path.join(folder, filename)
        try:
            img = Image.open(img_path).convert("RGB")
            images.append(img)
        except IOError:
            pass  # You can handle errors here if you want
    return images

# Image folder path
image_folder = '/content/drive/MyDrive/LoRA/advFe3'

# Load images
images = load_images_from_folder(image_folder)

# Initialize the processor and model
processor = AutoImageProcessor.from_pretrained('facebook/dinov2-base')
model = AutoModel.from_pretrained('facebook/dinov2-base')
model.config.return_dict = False

# Feature extraction
features = []
for image in images:
    inputs = processor(images=image, return_tensors="pt")
    with torch.no_grad():
        outputs = model(**inputs)
    # Flatten the tensor to 1D and convert to numpy
    features.append(outputs[0].squeeze().view(-1).numpy())

# Convert list of features to a 2D array
features_array = np.array(features)

# Clustering with K-MEANS++
n_clusters = 2  # Define the number of clusters
kmeans = KMeans(n_clusters=n_clusters, init='k-means++')
kmeans.fit(features_array)

# The cluster assignment for each image
clusters = kmeans.labels_

print("Cluster assignments:", clusters)

import numpy as np
import matplotlib.pyplot as plt
from sklearn.manifold import TSNE

# Dimensionality Reduction using t-SNE
n_samples = len(features_array)
perplexity_value = min(30, n_samples - 1)  # Ensure perplexity is less than the number of samples

tsne = TSNE(n_components=2, verbose=1, perplexity=perplexity_value, n_iter=300)
tsne_results = tsne.fit_transform(features_array)

# Visualization
plt.figure(figsize=(16,10))
scatter = plt.scatter(tsne_results[:,0], tsne_results[:,1], c=clusters, cmap='viridis')
plt.title('t-SNE visualization of image clusters')
plt.colorbar(scatter)
plt.show()

# Sort images by cluster assignment
sorted_indices = np.argsort(clusters)
sorted_images = [images[idx] for idx in sorted_indices]
sorted_clusters = clusters[sorted_indices]

# Get the count of images in each cluster
cluster_counts = np.bincount(sorted_clusters)

# Create a figure with subplots
fig, axes = plt.subplots(max(cluster_counts), len(np.unique(clusters)), figsize=(20, 60), squeeze=False)

# Plot each cluster in its column
for cluster_num in np.unique(sorted_clusters):
    cluster_indices = np.where(sorted_clusters == cluster_num)[0]
    for idx, img_idx in enumerate(cluster_indices):
        ax = axes[idx, cluster_num]
        ax.imshow(sorted_images[img_idx])
        ax.axis('off')
    for idx in range(len(cluster_indices), max(cluster_counts)):
        axes[idx, cluster_num].axis('off')

# Optionally, add a title to each column
for cluster_num in np.unique(sorted_clusters):
    axes[0, cluster_num].set_title(f'Cluster {cluster_num}')

plt.tight_layout()
plt.show()

def save_cluster_images(images, clusters, base_path):
    # Sort images by cluster assignment
    sorted_indices = np.argsort(clusters)
    sorted_images = [images[idx] for idx in sorted_indices]
    sorted_clusters = clusters[sorted_indices]

    # Iterate over each cluster and save images
    for cluster_num in np.unique(sorted_clusters):
        cluster_indices = np.where(sorted_clusters == cluster_num)[0]
        cluster_images = [sorted_images[idx] for idx in cluster_indices]

        # Create a directory for the cluster if it doesn't exist
        cluster_dir = os.path.join(base_path, f'cluster_{cluster_num}')
        os.makedirs(cluster_dir, exist_ok=True)

        # Save each image in the respective cluster directory
        for idx, img in enumerate(cluster_images):
            img_path = os.path.join(cluster_dir, f'image_{idx}.png')
            img.save(img_path)

save_cluster_images(images, clusters, image_folder)